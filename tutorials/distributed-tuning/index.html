<!DOCTYPE html>
<html lang="en">
    <head>
        <meta charset="utf-8">
        <meta http-equiv="X-UA-Compatible" content="IE=edge">
        <meta name="viewport" content="width=device-width, initial-scale=1.0">
        
        
        
        <link rel="shortcut icon" href="../../img/favicon.ico">
        <title>Distributed Tuning - Keras Tuner</title>
        <link href="../../css/bootstrap-custom.min.css" rel="stylesheet">
        <link href="../../css/font-awesome.min.css" rel="stylesheet">
        <link href="../../css/base.css" rel="stylesheet">
        <link rel="stylesheet" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/github.min.css">
        <link href="../../extra.css" rel="stylesheet">
        <!-- HTML5 shim and Respond.js IE8 support of HTML5 elements and media queries -->
        <!--[if lt IE 9]>
            <script src="https://oss.maxcdn.com/libs/html5shiv/3.7.0/html5shiv.js"></script>
            <script src="https://oss.maxcdn.com/libs/respond.js/1.4.2/respond.min.js"></script>
        <![endif]-->

        <script src="../../js/jquery-1.10.2.min.js" defer></script>
        <script src="../../js/bootstrap-3.0.3.min.js" defer></script>
        <script src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/highlight.min.js"></script>
        <script>hljs.initHighlightingOnLoad();</script> 
    </head>

    <body>

        <div class="navbar navbar-default navbar-fixed-top" role="navigation">
            <div class="container">

                <!-- Collapsed navigation -->
                <div class="navbar-header">
                    <!-- Expander button -->
                    <button type="button" class="navbar-toggle" data-toggle="collapse" data-target=".navbar-collapse">
                        <span class="sr-only">Toggle navigation</span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                        <span class="icon-bar"></span>
                    </button>
                    <a class="navbar-brand" href="../..">Keras Tuner</a>
                </div>

                <!-- Expanded navigation -->
                <div class="navbar-collapse collapse">
                        <!-- Main navigation -->
                        <ul class="nav navbar-nav">
                            <li >
                                <a href="../..">Home</a>
                            </li>
                            <li class="dropdown active">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Tutorials <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li class="active">
    <a href="./">Distributed Tuning</a>
</li>
                                    
<li >
    <a href="../subclass-tuner/">Subclassing Tuner for Custom Training Loops</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Documentation <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../documentation/hypermodels/">HyperModels</a>
</li>
                                    
<li >
    <a href="../../documentation/hyperparameters/">HyperParameters</a>
</li>
                                    
<li >
    <a href="../../documentation/oracles/">Oracles</a>
</li>
                                    
<li >
    <a href="../../documentation/tuners/">Tuners</a>
</li>
                                </ul>
                            </li>
                            <li class="dropdown">
                                <a href="#" class="dropdown-toggle" data-toggle="dropdown">Examples <b class="caret"></b></a>
                                <ul class="dropdown-menu">
                                    
<li >
    <a href="../../examples/helloworld/">Hello World</a>
</li>
                                </ul>
                            </li>
                            <li >
                                <a href="../../contributing/">Contributing Guide</a>
                            </li>
                        </ul>

                    <ul class="nav navbar-nav navbar-right">
                        <li>
                            <a href="#" data-toggle="modal" data-target="#mkdocs_search_modal">
                                <i class="fa fa-search"></i> Search
                            </a>
                        </li>
                            <li >
                                <a rel="next" href="../..">
                                    <i class="fa fa-arrow-left"></i> Previous
                                </a>
                            </li>
                            <li >
                                <a rel="prev" href="../subclass-tuner/">
                                    Next <i class="fa fa-arrow-right"></i>
                                </a>
                            </li>
                            <li>
                                <a href="https://github.com/keras-team/keras-tuner"><i class="fa fa-github"></i> GitHub</a>
                            </li>
                    </ul>
                </div>
            </div>
        </div>

        <div class="container">
                <div class="col-md-3"><div class="bs-sidebar hidden-print affix well" role="complementary">
    <ul class="nav bs-sidenav">
        <li class="main active"><a href="#distributed-tuning">Distributed Tuning</a></li>
            <li><a href="#configuring-distributed-mode">Configuring distributed mode</a></li>
            <li><a href="#data-parallelism-with-tfdistribute">Data parallelism with tf.distribute</a></li>
            <li><a href="#example-code">Example code</a></li>
    </ul>
</div></div>
                <div class="col-md-9" role="main">

<h1 id="distributed-tuning">Distributed Tuning</h1>
<p>Keras Tuner makes it easy to perform distributed hyperparameter search. No changes to your code are needed to scale up from running single-threaded locally to running on dozens or hundreds of workers in parallel. Distributed Keras Tuner uses a chief-worker model. The chief runs a service to which the workers report results and query for the hyperparameters to try next. The chief should be run on a single-threaded CPU instance (or alternatively as a separate process on one of the workers).</p>
<h3 id="configuring-distributed-mode">Configuring distributed mode</h3>
<p>Configuring distributed mode for Keras Tuner only requires setting three environment variables:</p>
<p><strong>KERASTUNER_TUNER_ID</strong>: This should be set to "chief" for the chief process. Other workers should be passed a unique ID (by convention, "tuner0", "tuner1", etc).</p>
<p><strong>KERASTUNER_ORACLE_IP</strong>: The IP address or hostname that the chief service should run on. All workers should be able to resolve and access this address.</p>
<p><strong>KERASTUNER_ORACLE_PORT</strong>: The port that the chief service should run on. This can be freely chosen, but must be a port that is accessible to the other workers. Instances communicate via the <a href="https://www.grpc.io">gRPC</a> protocol.</p>
<p>The same code can be run on all workers. Additional considerations for distributed mode are:</p>
<ul>
<li>All workers should have access to a centralized file system to which they can write their results.</li>
<li>All workers should be able to access the necessary training and validation data needed for tuning.</li>
<li>To support fault-tolerance, <code>overwrite</code> should be kept as <code>False</code> in <code>Tuner.__init__</code> (<code>False</code> is the default).</li>
</ul>
<p>Example bash script for chief service (sample code for <code>run_tuning.py</code> at bottom of page):</p>
<pre><code class="bash">export KERASTUNER_TUNER_ID=&quot;chief&quot;
export KERASTUNER_ORACLE_IP=&quot;127.0.0.1&quot;
export KERASTUNER_ORACLE_PORT=&quot;8000&quot;
python run_tuning.py
</code></pre>

<p>Example bash script for worker:</p>
<pre><code class="bash">export KERASTUNER_TUNER_ID=&quot;tuner0&quot;
export KERASTUNER_ORACLE_IP=&quot;127.0.0.1&quot;
export KERASTUNER_ORACLE_PORT=&quot;8000&quot;
python run_tuning.py
</code></pre>

<h3 id="data-parallelism-with-tfdistribute">Data parallelism with tf.distribute</h3>
<p>Keras Tuner also supports data parallelism via <a href="https://www.tensorflow.org/tutorials/distribute/keras">tf.distribute</a>. Data parallelism and distributed tuning can be combined. For example, if you have 10 workers with 4 GPUs on each worker, you can run 10 parallel trials with each trial training on 4 GPUs by using <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/MirroredStrategy">tf.distribute.MirroredStrategy</a>. You can also run each trial on TPUs via <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/TPUStrategy">tf.distribute.experimental.TPUStrategy</a>. Currently <a href="https://www.tensorflow.org/api_docs/python/tf/distribute/experimental/MultiWorkerMirroredStrategy">tf.distribute.MultiWorkerMirroredStrategy</a> is not supported, but support for this is on the roadmap.</p>
<h3 id="example-code">Example code</h3>
<p>When the enviroment variables described above are set, the example below will run distributed tuning and will also use data parallelism within each trial via <code>tf.distribute</code>. The example loads MNIST from <code>tensorflow_datasets</code> and uses hyperband for the hyperparameter search.</p>
<pre><code class="python">import kerastuner as kt
import tensorflow as tf
import tensorflow_datasets as tfds


def build_model(hp):
    &quot;&quot;&quot;Builds a convolutional model.&quot;&quot;&quot;
    inputs = tf.keras.Input(shape=(28, 28, 1))
    x = inputs
    for i in range(hp.Int('conv_layers', 1, 3, default=3)):
        x = tf.keras.layers.Conv2D(
            filters=hp.Int('filters_' + str(i), 4, 32, step=4, default=8),
            kernel_size=hp.Int('kernel_size_' + str(i), 3, 5),
            activation='relu',
            padding='same')(x)

        if hp.Choice('pooling' + str(i), ['max', 'avg']) == 'max':
            x = tf.keras.layers.MaxPooling2D()(x)
        else:
            x = tf.keras.layers.AveragePooling2D()(x)

        x = tf.keras.layers.BatchNormalization()(x)
        x = tf.keras.layers.ReLU()(x)

    if hp.Choice('global_pooling', ['max', 'avg']) == 'max':
        x = tf.keras.layers.GlobalMaxPooling2D()(x)
    else:
        x = tf.keras.layers.GlobalAveragePooling2D()(x)
    outputs = tf.keras.layers.Dense(10, activation='softmax')(x)

    model = tf.keras.Model(inputs, outputs)

    optimizer = hp.Choice('optimizer', ['adam', 'sgd'])
    model.compile(optimizer, loss='sparse_categorical_crossentropy', metrics=['accuracy'])
    return model


def convert_dataset(item):
    &quot;&quot;&quot;Puts the mnist dataset in the format Keras expects, (features, labels).&quot;&quot;&quot;
    image = item['image']
    label = item['label']
    image = tf.dtypes.cast(image, 'float32') / 255.
    return image, label


def main():
    &quot;&quot;&quot;Runs the hyperparameter search.&quot;&quot;&quot;
    tuner = kt.Hyperband(
        hypermodel=build_model,
        objective='val_accuracy',
        max_epochs=8,
        factor=2,
        hyperband_iterations=3,
        distribution_strategy=tf.distribute.MirroredStrategy(),
        directory='results_dir',
        project_name='mnist')

    mnist_data = tfds.load('mnist')
    mnist_train, mnist_test = mnist_data['train'], mnist_data['test']
    mnist_train = mnist_train.map(convert_dataset).shuffle(1000).batch(100).repeat()
    mnist_test = mnist_test.map(convert_dataset).batch(100)

    tuner.search(mnist_train,
                 steps_per_epoch=600,
                 validation_data=mnist_test,
                 validation_steps=100,
                 epochs=20,
                 callbacks=[tf.keras.callbacks.EarlyStopping('val_accuracy')])


if __name__ == '__main__':
    main()
</code></pre></div>
        </div>

        <footer class="col-md-12">
            <hr>
            <p>Documentation built with <a href="https://www.mkdocs.org/">MkDocs</a>.</p>
        </footer>
        <script>
            var base_url = "../..",
                shortcuts = {"help": 191, "next": 78, "previous": 80, "search": 83};
        </script>
        <script src="../../js/base.js" defer></script>
        <script src="../../search/main.js" defer></script>

        <div class="modal" id="mkdocs_search_modal" tabindex="-1" role="dialog" aria-labelledby="Search Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Search</h4>
            </div>
            <div class="modal-body">
                <p>
                    From here you can search these documents. Enter
                    your search terms below.
                </p>
                <form role="form">
                    <div class="form-group">
                        <input type="text" class="form-control" placeholder="Search..." id="mkdocs-search-query" title="Type search term here">
                    </div>
                </form>
                <div id="mkdocs-search-results"></div>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div><div class="modal" id="mkdocs_keyboard_modal" tabindex="-1" role="dialog" aria-labelledby="Keyboard Shortcuts Modal" aria-hidden="true">
    <div class="modal-dialog">
        <div class="modal-content">
            <div class="modal-header">
                <button type="button" class="close" data-dismiss="modal"><span aria-hidden="true">&times;</span><span class="sr-only">Close</span></button>
                <h4 class="modal-title" id="exampleModalLabel">Keyboard Shortcuts</h4>
            </div>
            <div class="modal-body">
              <table class="table">
                <thead>
                  <tr>
                    <th style="width: 20%;">Keys</th>
                    <th>Action</th>
                  </tr>
                </thead>
                <tbody>
                  <tr>
                    <td class="help shortcut"><kbd>?</kbd></td>
                    <td>Open this help</td>
                  </tr>
                  <tr>
                    <td class="next shortcut"><kbd>n</kbd></td>
                    <td>Next page</td>
                  </tr>
                  <tr>
                    <td class="prev shortcut"><kbd>p</kbd></td>
                    <td>Previous page</td>
                  </tr>
                  <tr>
                    <td class="search shortcut"><kbd>s</kbd></td>
                    <td>Search</td>
                  </tr>
                </tbody>
              </table>
            </div>
            <div class="modal-footer">
            </div>
        </div>
    </div>
</div>

    </body>
</html>
